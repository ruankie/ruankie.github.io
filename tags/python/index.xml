<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on Ruan Pretorius</title>
    <link>https://ruankie.github.io/tags/python/</link>
    <description>Recent content in Python on Ruan Pretorius</description>
    <generator>Hugo 0.125.2</generator>
    <language>en</language>
    <lastBuildDate>Thu, 03 Oct 2024 12:00:00 +0200</lastBuildDate>
    <atom:link href="https://ruankie.github.io/tags/python/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>PyConZA: Monitoring and Evaluating LLM Apps with Langfuse</title>
      <link>https://ruankie.github.io/publications/pyconza-24/</link>
      <pubDate>Thu, 03 Oct 2024 12:00:00 +0200</pubDate>
      <guid>https://ruankie.github.io/publications/pyconza-24/</guid>
      <description>Links ðŸ“¦ Repository ðŸ“Š Slides Abstract In the rapidly evolving landscape of AI, the ability to quickly iterate on prototypes and ensure robust performance of apps built around language models is crucial for developers and data scientists. This talk focuses on leveraging free and open-source tools to build, monitor, and evaluate LLM applications, providing a cost-effective approach to rapid development and deployment within the Python ecosystem.&#xA;Topics Covered Setting up local LLMs for fast prototyping Using Ollama for easy setup and deployment on local machines Running LLMs locally to build and test prototypes without incurring costs Monitoring LLM apps with Langfuse Introduction to Langfuse, an open-source LLM engineering platform Configuring Langfuse for tracing and evaluation Implementing Langfuse&amp;rsquo;s Python decorator and SDK for detailed monitoring LLM-assisted evaluation Using Langfuse to set up evaluation datasets and scoring responses of your LLM app Target Audience and Takeaways This talk is aimed at developers and data scientists who are interested in monitoring and optimising their LLM applications.</description>
    </item>
    <item>
      <title>PyData Global: How to build a data pipeline without data</title>
      <link>https://ruankie.github.io/publications/pydata-23/</link>
      <pubDate>Wed, 06 Dec 2023 16:00:00 +0200</pubDate>
      <guid>https://ruankie.github.io/publications/pydata-23/</guid>
      <description>Links ðŸ“¦ Repository ðŸ“Š Slides Abstract Data pipelines are essential for transforming, validating, and loading data from various sources into a target database or data warehouse. However, building and testing data pipelines can be challenging when the real data is not available, either due to privacy issues, technical limitations, or simply because the data is not yet collected. How can we ensure that our data pipelines are robust and reliable without having access to the actual data?</description>
    </item>
    <item>
      <title>PyConZA: How to build a data pipeline without data</title>
      <link>https://ruankie.github.io/publications/pyconza-23/</link>
      <pubDate>Thu, 05 Oct 2023 11:00:00 +0200</pubDate>
      <guid>https://ruankie.github.io/publications/pyconza-23/</guid>
      <description>Links ðŸ“¦ Repository ðŸ“Š Slides Abstract Data pipelines are essential for transforming, validating, and loading data from various sources into a target database or data warehouse. However, building and testing data pipelines can be challenging when the real data is not available, either due to privacy issues, technical limitations, or simply because the data is not yet collected. How can we ensure that our data pipelines are robust and reliable without having access to the actual data?</description>
    </item>
    <item>
      <title>Deep Reinforcement Learning and Convex Mean-Variance Optimisation for Portfolio Management</title>
      <link>https://ruankie.github.io/publications/rl-pm-msc/</link>
      <pubDate>Tue, 22 Feb 2022 16:21:29 +0200</pubDate>
      <guid>https://ruankie.github.io/publications/rl-pm-msc/</guid>
      <description>See full paper here&#xA;Abstract Traditional portfolio management methods can incorporate specific investor preferences but rely on accurate forecasts of asset returns and covariances. Reinforcement learning (RL) methods do not rely on these explicit forecasts and are better suited for multi-stage decision processes. To address limitations of the evaluated research, experiments were conducted on three markets in different economies with different overall trends. By incorporating specific investor preferences into our RL modelsâ€™ reward functions, a more comprehensive comparison could be made to traditional methods in risk-return space.</description>
    </item>
  </channel>
</rss>
